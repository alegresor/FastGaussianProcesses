{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Lattice GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastgp\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (128, 2)\n",
      "y.shape = (3, 128)\n",
      "z.shape = (256, 2)\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "f = lambda x: x[:,1]*torch.sin(x[:,0])+x[:,0]*torch.cos(x[:,1])\n",
    "f0 = lambda x: x[:,1]*torch.cos(x[:,0])+torch.cos(x[:,1])\n",
    "f1 = lambda x: torch.sin(x[:,0])-x[:,0]*torch.sin(x[:,1])\n",
    "derivatives = [\n",
    "    torch.tensor([0,0]),\n",
    "    torch.tensor([1,0]),\n",
    "    torch.tensor([0,1]),\n",
    "]\n",
    "rng = torch.Generator().manual_seed(17)\n",
    "x = torch.rand((2**7,d),generator=rng) # random testing locations\n",
    "y = torch.cat([f(x)[None,:],f0(x)[None,:],f1(x)[None,:]],dim=0) # true values at random testing locations\n",
    "z = torch.rand((2**8,d),generator=rng) # other random locations at which to evaluate covariance\n",
    "print(\"x.shape = %s\"%str(tuple(x.shape)))\n",
    "print(\"y.shape = %s\"%str(tuple(y.shape)))\n",
    "print(\"z.shape = %s\"%str(tuple(z.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Fast GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "\tx_next[0].shape = (64, 2)\n",
      "\ty_next[0].shape = (64,)\n",
      "i = 1\n",
      "\tx_next[1].shape = (8, 2)\n",
      "\ty_next[1].shape = (8,)\n",
      "i = 2\n",
      "\tx_next[2].shape = (256, 2)\n",
      "\ty_next[2].shape = (256,)\n"
     ]
    }
   ],
   "source": [
    "fgp = fastgp.FastGPLattice(d,seed_for_seq=7,num_tasks=len(derivatives),derivatives=derivatives,alpha=4)\n",
    "x_next = fgp.get_x_next(n=[2**6,2**3,2**8])\n",
    "y_next = [f(x_next[0]),f0(x_next[1]),f1(x_next[2])]\n",
    "fgp.add_y_next(y_next)\n",
    "assert len(x_next)==len(y_next)\n",
    "for i in range(len(x_next)):\n",
    "    print(\"i = %d\"%i)\n",
    "    print(\"\\tx_next[%d].shape = %s\"%(i,str(tuple(x_next[i].shape))))\n",
    "    print(\"\\ty_next[%d].shape = %s\"%(i,str(tuple(y_next[i].shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean.shape = (3, 128)\n",
      "l2 relative error = tensor([0.2546, 1.2280, 1.0843])\n"
     ]
    }
   ],
   "source": [
    "pmean = fgp.post_mean(x)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "print(\"l2 relative error =\",(torch.linalg.norm(y-pmean,dim=1)/torch.linalg.norm(y,dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iter of 5.0e+03 | NMLL       | norm term  | logdet term\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "            0.00e+00 | 2.91e+06   | 2.92e+06   | -1.82e+03 \n",
      "            5.00e+00 | 3.66e+05   | 3.67e+05   | -1.12e+03 \n",
      "            1.00e+01 | 4.12e+03   | 2.90e+03   | 6.09e+02  \n",
      "            1.50e+01 | 2.46e+03   | 7.40e+02   | 1.12e+03  \n",
      "            2.00e+01 | 2.32e+03   | 3.67e+02   | 1.35e+03  \n",
      "            2.50e+01 | 2.16e+03   | 3.35e+02   | 1.23e+03  \n",
      "            3.00e+01 | 2.06e+03   | 3.06e+02   | 1.15e+03  \n",
      "            3.50e+01 | 2.05e+03   | 3.12e+02   | 1.14e+03  \n",
      "            4.00e+01 | 2.05e+03   | 3.06e+02   | 1.14e+03  \n",
      "            4.50e+01 | 2.05e+03   | 3.20e+02   | 1.13e+03  \n",
      "            5.00e+01 | 2.05e+03   | 3.28e+02   | 1.12e+03  \n",
      "            5.50e+01 | 2.05e+03   | 3.21e+02   | 1.13e+03  \n",
      "            6.00e+01 | 2.05e+03   | 3.27e+02   | 1.12e+03  \n",
      "            6.50e+01 | 2.05e+03   | 3.25e+02   | 1.12e+03  \n",
      "            7.00e+01 | 2.05e+03   | 3.25e+02   | 1.12e+03  \n",
      "            7.50e+01 | 2.05e+03   | 3.25e+02   | 1.12e+03  \n",
      "            8.00e+01 | 2.04e+03   | 3.26e+02   | 1.12e+03  \n",
      "            8.50e+01 | 2.04e+03   | 3.27e+02   | 1.11e+03  \n",
      "            9.00e+01 | 2.08e+03   | 1.85e+02   | 1.29e+03  \n",
      "            9.50e+01 | 2.04e+03   | 3.88e+02   | 1.05e+03  \n",
      "            1.00e+02 | 2.03e+03   | 3.19e+02   | 1.11e+03  \n",
      "            1.05e+02 | 2.03e+03   | 3.16e+02   | 1.11e+03  \n",
      "            1.10e+02 | 2.03e+03   | 3.23e+02   | 1.11e+03  \n",
      "            1.15e+02 | 2.03e+03   | 3.28e+02   | 1.10e+03  \n",
      "            1.16e+02 | 2.03e+03   | 3.26e+02   | 1.10e+03  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mll_hist', 'scale_hist', 'lengthscales_hist']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fgp.fit()\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean.shape = (3, 128)\n",
      "pvar.shape = (3, 128)\n",
      "q = 2.58\n",
      "ci_low.shape = (3, 128)\n",
      "ci_high.shape = (3, 128)\n",
      "l2 relative error = tensor([0.5039, 1.2303, 1.0848])\n",
      "pcov.shape = (3, 3, 128, 128)\n",
      "pcov2.shape = (3, 3, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "pmean,pvar,q,ci_low,ci_high = fgp.post_ci(x,confidence=0.99)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "print(\"pvar.shape = %s\"%str(tuple(pvar.shape)))\n",
    "print(\"q = %.2f\"%q)\n",
    "print(\"ci_low.shape = %s\"%str(tuple(ci_low.shape)))\n",
    "print(\"ci_high.shape = %s\"%str(tuple(ci_high.shape)))\n",
    "print(\"l2 relative error =\",(torch.linalg.norm(y-pmean,dim=1)/torch.linalg.norm(y,dim=1)))\n",
    "pcov = fgp.post_cov(x,x)\n",
    "print(\"pcov.shape = %s\"%str(tuple(pcov.shape)))\n",
    "_range0,_rangen1 = torch.arange(pcov.size(0)),torch.arange(pcov.size(-1))\n",
    "assert torch.allclose(pcov[_range0,_range0][:,_rangen1,_rangen1],pvar) and (pvar>=0).all()\n",
    "pcov2 = fgp.post_cov(x,z)\n",
    "print(\"pcov2.shape = %s\"%str(tuple(pcov2.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcmean = tensor([6.4593e-01, 2.3159e-04, 1.2576e+02])\n",
      "pcvar = tensor([1.2704e-04, 2.1508e-01, 0.0000e+00])\n",
      "cci_low = tensor([  0.6169,  -1.1944, 125.7643])\n",
      "cci_high tensor([  0.6750,   1.1948, 125.7643])\n"
     ]
    }
   ],
   "source": [
    "pcmean,pcvar,q,cci_low,cci_high = fgp.post_cubature_ci(confidence=0.99)\n",
    "print(\"pcmean =\",pcmean)\n",
    "print(\"pcvar =\",pcvar)\n",
    "print(\"cci_low =\",cci_low)\n",
    "print(\"cci_high\",cci_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and Increase Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = fgp.n*torch.tensor([4,2,8])\n",
    "pcov_future = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_future = fgp.post_var(x,n=n_new)\n",
    "pcvar_future = fgp.post_cubature_var(n=n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192])\n",
      "torch.Size([8])\n",
      "torch.Size([1792])\n",
      "l2 relative error = tensor([0.2613, 1.1435, 0.4627])\n"
     ]
    }
   ],
   "source": [
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(x_next[0]),f0(x_next[1]),f1(x_next[2])]\n",
    "for _y in y_next:\n",
    "    print(_y.shape)\n",
    "fgp.add_y_next(y_next)\n",
    "print(\"l2 relative error =\",(torch.linalg.norm(y-fgp.post_mean(x),dim=1)/torch.linalg.norm(y,dim=1)))\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_future)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_future)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 relative error = tensor([0.2028, 1.1339, 0.8745])\n"
     ]
    }
   ],
   "source": [
    "data = fgp.fit(verbose=False,store_mll_hist=False,store_scale_hist=False,store_lengthscales_hist=False,store_noise_hist=False)\n",
    "print(\"l2 relative error =\",(torch.linalg.norm(y-fgp.post_mean(x),dim=1)/torch.linalg.norm(y,dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = fgp.n*torch.tensor([4,8,2])\n",
    "pcov_new = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_new = fgp.post_var(x,n=n_new)\n",
    "pcvar_new = fgp.post_cubature_var(n=n_new)\n",
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(x_next[0]),f0(x_next[1]),f1(x_next[2])]\n",
    "fgp.add_y_next(y_next)\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_new)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_new)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
