{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Batch Multitask Net GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastgp\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (128, 3)\n",
      "y.shape = (4, 3, 5, 6, 128)\n",
      "z.shape = (256, 3)\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "rng = torch.Generator().manual_seed(7)\n",
    "shape_batch = [4,5,6]\n",
    "num_tasks = 3 \n",
    "def f(l, x):\n",
    "    consts = torch.arange(torch.prod(torch.tensor(shape_batch))).reshape(shape_batch)\n",
    "    y = (consts[...,None,None]*x**torch.arange(1,d+1)).sum(-1)+torch.randn(shape_batch+[x.size(0)],generator=rng)/(3+l)\n",
    "    return y\n",
    "x = torch.rand((2**7,d),generator=rng) # random testing locations\n",
    "y = torch.cat([f(l,x)[:,None,:] for l in range(num_tasks)],1) # true values at random testing locations\n",
    "z = torch.rand((2**8,d),generator=rng) # other random locations at which to evaluate covariance\n",
    "print(\"x.shape = %s\"%str(tuple(x.shape)))\n",
    "print(\"y.shape = %s\"%str(tuple(y.shape)))\n",
    "print(\"z.shape = %s\"%str(tuple(z.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Fast GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgp.scale.shape = (4, 5, 6, 1)\n",
      "fgp.lengthscales.shape = (5, 6, 3)\n",
      "fgp.noise.shape = (6, 1)\n",
      "fgp.factor_task_kernel.shape = (4, 5, 6, 3, 3)\n",
      "fgp.noise_task_kernel.shape = (5, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "fgp = fastgp.FastGPDigitalNetB2(d,seed_for_seq=7,num_tasks=num_tasks,\n",
    "    shape_batch=shape_batch,\n",
    "    shape_scale = shape_batch[:]+[1],\n",
    "    shape_lengthscales = shape_batch[1:]+[d],\n",
    "    shape_noise = shape_batch[2:]+[1],\n",
    "    shape_factor_task_kernel = shape_batch[:]+[num_tasks,num_tasks],\n",
    "    shape_noise_task_kernel = shape_batch[1:]+[num_tasks]\n",
    ")\n",
    "print(\"fgp.scale.shape = %s\"%str(tuple(fgp.scale.shape)))\n",
    "print(\"fgp.lengthscales.shape = %s\"%str(tuple(fgp.lengthscales.shape)))\n",
    "print(\"fgp.noise.shape = %s\"%str(tuple(fgp.noise.shape)))\n",
    "print(\"fgp.factor_task_kernel.shape = %s\"%str(tuple(fgp.factor_task_kernel.shape)))\n",
    "print(\"fgp.noise_task_kernel.shape = %s\"%str(tuple(fgp.noise_task_kernel.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "\tx_next[0].shape = (4, 3)\n",
      "\ty_next[0].shape = (4, 5, 6, 4)\n",
      "i = 1\n",
      "\tx_next[1].shape = (2, 3)\n",
      "\ty_next[1].shape = (4, 5, 6, 2)\n",
      "i = 2\n",
      "\tx_next[2].shape = (1, 3)\n",
      "\ty_next[2].shape = (4, 5, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "x_next = fgp.get_x_next(n=2**torch.arange(num_tasks-1,-1,-1))\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "fgp.add_y_next(y_next)\n",
    "for i in range(len(x_next)):  \n",
    "    print(\"i = %d\"%i)\n",
    "    print(\"\\tx_next[%d].shape = %s\"%(i,str(tuple(x_next[i].shape))))\n",
    "    print(\"\\ty_next[%d].shape = %s\"%(i,str(tuple(y_next[i].shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (5) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pmean = \u001b[43mfgp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpmean.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m%\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(pmean.shape)))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33ml2 relative error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m%\u001b[38;5;28mstr\u001b[39m(torch.linalg.norm(y-pmean,dim=-\u001b[32m1\u001b[39m)/torch.linalg.norm(y,dim=-\u001b[32m1\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FastGaussianProcesses/fastgp/abstract_fast_gp.py:304\u001b[39m, in \u001b[36mAbstractFastGP.post_mean\u001b[39m\u001b[34m(self, x, task, eval)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost_mean\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:torch.Tensor, task:Union[\u001b[38;5;28mint\u001b[39m,torch.Tensor]=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28meval\u001b[39m:\u001b[38;5;28mbool\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    293\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m    Posterior mean. \u001b[39;00m\n\u001b[32m    295\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m \u001b[33;03m        pmean (torch.Tensor[...,T,N]): posterior mean\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     coeffs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoeffs\u001b[49m\n\u001b[32m    305\u001b[39m     kmat_tasks = \u001b[38;5;28mself\u001b[39m.gram_matrix_tasks\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28meval\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FastGaussianProcesses/fastgp/abstract_fast_gp.py:629\u001b[39m, in \u001b[36mAbstractFastGP.coeffs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;129m@property\u001b[39m \n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoeffs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    626\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[33;03m    Coefficients $\\mathsf{K}^{-1} \\boldsymbol{y}$.\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoeffs_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FastGaussianProcesses/fastgp/util.py:299\u001b[39m, in \u001b[36m_CoeffsCache.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcoeffs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.n!=\u001b[38;5;28mself\u001b[39m.fgp.n).any() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._frozen_equal() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._force_recompile():\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m         \u001b[38;5;28mself\u001b[39m.coeffs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfgp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_inv_log_det_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgram_matrix_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfgp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[...,\u001b[32m0\u001b[39m]\n\u001b[32m    300\u001b[39m         \u001b[38;5;28mself\u001b[39m._freeze()\n\u001b[32m    301\u001b[39m         \u001b[38;5;28mself\u001b[39m.n = \u001b[38;5;28mself\u001b[39m.fgp.n.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FastGaussianProcesses/fastgp/util.py:250\u001b[39m, in \u001b[36m_InverseLogDetCache.gram_matrix_solve\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    248\u001b[39m zs = z.split(\u001b[38;5;28mself\u001b[39m.n.tolist(),dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    249\u001b[39m zst = [\u001b[38;5;28mself\u001b[39m.fgp.ft(zs[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.fgp.num_tasks)]\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m zst,_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gram_matrix_solve_tilde_to_tilde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m zs = [\u001b[38;5;28mself\u001b[39m.fgp.ift(zst[i]).real \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.fgp.num_tasks)]\n\u001b[32m    252\u001b[39m z = torch.cat(zs,dim=-\u001b[32m1\u001b[39m).transpose(dim0=-\u001b[32m2\u001b[39m,dim1=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FastGaussianProcesses/fastgp/util.py:268\u001b[39m, in \u001b[36m_InverseLogDetCache._gram_matrix_solve_tilde_to_tilde\u001b[39m\u001b[34m(self, zst)\u001b[39m\n\u001b[32m    266\u001b[39m zsto = [zst[o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task_order]\n\u001b[32m    267\u001b[39m z = torch.cat(zsto,dim=-\u001b[32m1\u001b[39m).reshape(\u001b[38;5;28mlist\u001b[39m(zsto[\u001b[32m0\u001b[39m].shape[:-\u001b[32m1\u001b[39m])+[\u001b[32m1\u001b[39m,-\u001b[32m1\u001b[39m,\u001b[38;5;28mself\u001b[39m.n[\u001b[38;5;28mself\u001b[39m.n>\u001b[32m0\u001b[39m].min()])\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m z = (\u001b[43mz\u001b[49m\u001b[43m*\u001b[49m\u001b[43minv\u001b[49m).sum(-\u001b[32m2\u001b[39m)\n\u001b[32m    269\u001b[39m z = z.reshape(\u001b[38;5;28mlist\u001b[39m(z.shape[:-\u001b[32m2\u001b[39m])+[-\u001b[32m1\u001b[39m])\n\u001b[32m    270\u001b[39m zsto = z.split(\u001b[38;5;28mself\u001b[39m.n[\u001b[38;5;28mself\u001b[39m.task_order].tolist(),dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (6) must match the size of tensor b (5) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "pmean = fgp.post_mean(x)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "print(\"l2 relative error:\\n%s\"%str(torch.linalg.norm(y-pmean,dim=-1)/torch.linalg.norm(y,dim=-1)))\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iter of 5.0e+03 | NMLL       | norm term  | logdet term\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "            0.00e+00 | 4.78e+02   | 7.77e+00   | -4.12e+02 \n",
      "            5.00e+00 | -6.52e+02  | 1.57e+02   | -1.69e+03 \n",
      "            1.00e+01 | -9.28e+02  | 2.82e+02   | -2.09e+03 \n",
      "            1.50e+01 | -1.04e+03  | 4.64e+02   | -2.38e+03 \n",
      "            2.00e+01 | -1.10e+03  | 4.71e+02   | -2.46e+03 \n",
      "            2.50e+01 | -1.14e+03  | 4.85e+02   | -2.51e+03 \n",
      "            3.00e+01 | -1.17e+03  | 4.92e+02   | -2.55e+03 \n",
      "            3.50e+01 | -1.18e+03  | 4.84e+02   | -2.55e+03 \n",
      "            4.00e+01 | -1.18e+03  | 4.82e+02   | -2.55e+03 \n",
      "            4.50e+01 | -1.18e+03  | 4.73e+02   | -2.54e+03 \n",
      "            5.00e+01 | -1.18e+03  | 4.75e+02   | -2.54e+03 \n",
      "            5.50e+01 | -1.18e+03  | 4.77e+02   | -2.54e+03 \n",
      "            6.00e+01 | -1.19e+03  | 4.78e+02   | -2.55e+03 \n",
      "            6.50e+01 | -1.19e+03  | 4.78e+02   | -2.55e+03 \n",
      "            7.00e+01 | -1.19e+03  | 4.79e+02   | -2.56e+03 \n",
      "            7.50e+01 | -1.21e+03  | 4.77e+02   | -2.57e+03 \n",
      "            8.00e+01 | -1.08e+02  | 2.35e+03   | -3.34e+03 \n",
      "            8.50e+01 | -1.21e+03  | 5.46e+02   | -2.64e+03 \n",
      "            8.90e+01 | -1.21e+03  | 5.68e+02   | -2.66e+03 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mll_hist', 'scale_hist', 'lengthscales_hist', 'task_kernel_hist']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fgp.fit()\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean.shape = (2, 4, 128)\n",
      "pvar.shape = (4, 128)\n",
      "q = 2.58\n",
      "ci_low.shape = (2, 4, 128)\n",
      "ci_high.shape = (2, 4, 128)\n",
      "l2 relative error:\n",
      "tensor([[0.1350, 0.0766, 0.0542, 0.0448],\n",
      "        [0.1758, 0.0942, 0.0681, 0.0656]])\n",
      "pcov.shape = (4, 4, 128, 128)\n",
      "pcov2.shape = (4, 4, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "pmean,pvar,q,ci_low,ci_high = fgp.post_ci(x,confidence=0.99)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "print(\"pvar.shape = %s\"%str(tuple(pvar.shape)))\n",
    "print(\"q = %.2f\"%q)\n",
    "print(\"ci_low.shape = %s\"%str(tuple(ci_low.shape)))\n",
    "print(\"ci_high.shape = %s\"%str(tuple(ci_high.shape)))\n",
    "print(\"l2 relative error:\\n%s\"%str(torch.linalg.norm(y-pmean,dim=-1)/torch.linalg.norm(y,dim=-1)))\n",
    "pcov = fgp.post_cov(x,x)\n",
    "print(\"pcov.shape = %s\"%str(tuple(pcov.shape)))\n",
    "_range0,_rangen1 = torch.arange(pcov.size(0)),torch.arange(pcov.size(-1))\n",
    "assert torch.allclose(pcov[_range0,_range0][:,_rangen1,_rangen1],pvar) and (pvar>=0).all()\n",
    "pcov2 = fgp.post_cov(x,z)\n",
    "print(\"pcov2.shape = %s\"%str(tuple(pcov2.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcmean:\n",
      "tensor([[ 9.6223e-19,  3.7947e-19,  4.8789e-19,  6.7763e-19],\n",
      "        [-4.7976e-18, -6.6678e-18, -1.0354e-17, -9.7578e-18]])\n",
      "\n",
      "pcvar:\n",
      "tensor([1.6881e-05, 1.4482e-05, 1.2366e-05, 1.2779e-05])\n",
      "\n",
      "cci_low:\n",
      "tensor([[-0.0106, -0.0098, -0.0091, -0.0092],\n",
      "        [-0.0106, -0.0098, -0.0091, -0.0092]])\n",
      "\n",
      "cci_high:\n",
      "tensor([[0.0106, 0.0098, 0.0091, 0.0092],\n",
      "        [0.0106, 0.0098, 0.0091, 0.0092]])\n"
     ]
    }
   ],
   "source": [
    "pcmean,pcvar,q,cci_low,cci_high = fgp.post_cubature_ci(confidence=0.99)\n",
    "print(\"pcmean:\\n%s\"%str(pcmean))\n",
    "print(\"\\npcvar:\\n%s\"%str(pcvar))\n",
    "print(\"\\ncci_low:\\n%s\"%str(cci_low))\n",
    "print(\"\\ncci_high:\\n%s\"%str(cci_high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and Increase Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = fgp.n*2**torch.arange(num_tasks-1,-1,-1)\n",
    "pcov_future = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_future = fgp.post_var(x,n=n_new)\n",
    "pcvar_future = fgp.post_cubature_var(n=n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 112])\n",
      "torch.Size([2, 96])\n",
      "torch.Size([2, 64])\n",
      "torch.Size([2, 0])\n",
      "l2 relative error:\n",
      "tensor([[0.0386, 0.0370, 0.0470, 0.0491],\n",
      "        [0.0403, 0.0364, 0.0603, 0.0727]])\n"
     ]
    }
   ],
   "source": [
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "for _y in y_next:\n",
    "    print(_y.shape)\n",
    "fgp.add_y_next(y_next)\n",
    "print(\"l2 relative error:\\n%s\"%str(torch.linalg.norm(y-fgp.post_mean(x),dim=-1)/torch.linalg.norm(y,dim=-1)))\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_future)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_future)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 relative error:\n",
      "tensor([[0.0343, 0.0365, 0.0317, 0.0400],\n",
      "        [0.0343, 0.0355, 0.0520, 0.0677]])\n"
     ]
    }
   ],
   "source": [
    "data = fgp.fit(verbose=False,store_mll_hist=False,store_scale_hist=False,store_lengthscales_hist=False,store_noise_hist=False)\n",
    "print(\"l2 relative error:\\n%s\"%str(torch.linalg.norm(y-fgp.post_mean(x),dim=-1)/torch.linalg.norm(y,dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = fgp.n*2**torch.arange(num_tasks)\n",
    "pcov_new = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_new = fgp.post_var(x,n=n_new)\n",
    "pcvar_new = fgp.post_cubature_var(n=n_new)\n",
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "fgp.add_y_next(y_next)\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_new)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_new)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
