{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Batch Multitask Lattice GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:45.921841Z",
     "iopub.status.busy": "2025-04-25T22:13:45.921505Z",
     "iopub.status.idle": "2025-04-25T22:13:47.131029Z",
     "shell.execute_reply": "2025-04-25T22:13:47.130721Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastgps\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.132611Z",
     "iopub.status.busy": "2025-04-25T22:13:47.132359Z",
     "iopub.status.idle": "2025-04-25T22:13:47.134047Z",
     "shell.execute_reply": "2025-04-25T22:13:47.133867Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.135050Z",
     "iopub.status.busy": "2025-04-25T22:13:47.134973Z",
     "iopub.status.idle": "2025-04-25T22:13:47.138312Z",
     "shell.execute_reply": "2025-04-25T22:13:47.138133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (128, 6)\n",
      "y.shape = (2, 3, 4, 5, 128)\n",
      "z.shape = (64, 6)\n"
     ]
    }
   ],
   "source": [
    "d = 6\n",
    "rng = torch.Generator().manual_seed(7)\n",
    "shape_batch = [2,3,4]\n",
    "num_tasks = 5 \n",
    "def f(l, x):\n",
    "    consts = torch.arange(torch.prod(torch.tensor(shape_batch))).reshape(shape_batch)\n",
    "    y = (consts[...,None,None]*x**torch.arange(1,d+1)).sum(-1)+torch.randn(shape_batch+[x.size(0)],generator=rng)/(3+l)\n",
    "    return y\n",
    "x = torch.rand((2**7,d),generator=rng) # random testing locations\n",
    "y = torch.cat([f(l,x)[...,None,:] for l in range(num_tasks)],-2) # true values at random testing locations\n",
    "z = torch.rand((2**6,d),generator=rng) # other random locations at which to evaluate covariance\n",
    "print(\"x.shape = %s\"%str(tuple(x.shape)))\n",
    "print(\"y.shape = %s\"%str(tuple(y.shape)))\n",
    "print(\"z.shape = %s\"%str(tuple(z.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Fast GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.154024Z",
     "iopub.status.busy": "2025-04-25T22:13:47.153922Z",
     "iopub.status.idle": "2025-04-25T22:13:47.164854Z",
     "shell.execute_reply": "2025-04-25T22:13:47.164661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgp.scale.shape = (2, 3, 4, 1)\n",
      "fgp.lengthscales.shape = (3, 4, 6)\n",
      "fgp.noise.shape = (4, 1)\n",
      "fgp.factor_task_kernel.shape = (2, 3, 4, 5, 5)\n",
      "fgp.noise_task_kernel.shape = (3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "fgp = fastgps.FastGPLattice(d,seed_for_seq=7,num_tasks=num_tasks,\n",
    "    shape_batch=shape_batch,\n",
    "    shape_scale = shape_batch[:]+[1],\n",
    "    shape_lengthscales = shape_batch[1:]+[d],\n",
    "    shape_noise = shape_batch[2:]+[1],\n",
    "    shape_factor_task_kernel = shape_batch[:]+[num_tasks,num_tasks],\n",
    "    shape_noise_task_kernel = shape_batch[1:]+[num_tasks]\n",
    ")\n",
    "print(\"fgp.scale.shape = %s\"%str(tuple(fgp.scale.shape)))\n",
    "print(\"fgp.lengthscales.shape = %s\"%str(tuple(fgp.lengthscales.shape)))\n",
    "print(\"fgp.noise.shape = %s\"%str(tuple(fgp.noise.shape)))\n",
    "print(\"fgp.factor_task_kernel.shape = %s\"%str(tuple(fgp.factor_task_kernel.shape)))\n",
    "print(\"fgp.noise_task_kernel.shape = %s\"%str(tuple(fgp.noise_task_kernel.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.165852Z",
     "iopub.status.busy": "2025-04-25T22:13:47.165768Z",
     "iopub.status.idle": "2025-04-25T22:13:47.168864Z",
     "shell.execute_reply": "2025-04-25T22:13:47.168673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "\tx_next[0].shape = (64, 6)\n",
      "\ty_next[0].shape = (2, 3, 4, 64)\n",
      "i = 1\n",
      "\tx_next[1].shape = (32, 6)\n",
      "\ty_next[1].shape = (2, 3, 4, 32)\n",
      "i = 2\n",
      "\tx_next[2].shape = (16, 6)\n",
      "\ty_next[2].shape = (2, 3, 4, 16)\n",
      "i = 3\n",
      "\tx_next[3].shape = (8, 6)\n",
      "\ty_next[3].shape = (2, 3, 4, 8)\n",
      "i = 4\n",
      "\tx_next[4].shape = (4, 6)\n",
      "\ty_next[4].shape = (2, 3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "x_next = fgp.get_x_next(n=2**torch.arange(num_tasks+1,1,-1))\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "fgp.add_y_next(y_next)\n",
    "for i in range(len(x_next)):  \n",
    "    print(\"i = %d\"%i)\n",
    "    print(\"\\tx_next[%d].shape = %s\"%(i,str(tuple(x_next[i].shape))))\n",
    "    print(\"\\ty_next[%d].shape = %s\"%(i,str(tuple(y_next[i].shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.169918Z",
     "iopub.status.busy": "2025-04-25T22:13:47.169839Z",
     "iopub.status.idle": "2025-04-25T22:13:47.229721Z",
     "shell.execute_reply": "2025-04-25T22:13:47.229504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean.shape = (2, 3, 4, 5, 128)\n",
      "l2rerror.shape = (2, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "pmean = fgp.post_mean(x)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "l2rerror = torch.linalg.norm(y-pmean,dim=-1)/torch.linalg.norm(y,dim=-1)\n",
    "print(\"l2rerror.shape = %s\"%str(tuple(l2rerror.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:47.230940Z",
     "iopub.status.busy": "2025-04-25T22:13:47.230855Z",
     "iopub.status.idle": "2025-04-25T22:13:49.270496Z",
     "shell.execute_reply": "2025-04-25T22:13:49.270214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iter of 5.0e+03 | loss       | term1      | term2     \n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "            0.00e+00 | 1.58e+04   | 2.71e+02   | 2.58e+04  \n",
      "            5.00e+00 | 1.22e+04   | 5.22e+03   | 1.36e+04  \n",
      "            1.00e+01 | 1.00e+04   | 3.58e+03   | 1.10e+04  \n",
      "            1.50e+01 | 9.29e+03   | 3.54e+03   | 9.56e+03  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            2.00e+01 | 8.91e+03   | 3.39e+03   | 8.95e+03  \n",
      "            2.50e+01 | 8.64e+03   | 3.31e+03   | 8.50e+03  \n",
      "            3.00e+01 | 8.45e+03   | 3.30e+03   | 8.14e+03  \n",
      "            3.50e+01 | 8.37e+03   | 3.17e+03   | 8.10e+03  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            4.00e+01 | 8.31e+03   | 3.06e+03   | 8.10e+03  \n",
      "            4.50e+01 | 8.28e+03   | 3.09e+03   | 8.00e+03  \n",
      "            5.00e+01 | 8.25e+03   | 3.08e+03   | 7.95e+03  \n",
      "            5.50e+01 | 8.24e+03   | 3.07e+03   | 7.93e+03  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            6.00e+01 | 8.22e+03   | 3.07e+03   | 7.90e+03  \n",
      "            6.50e+01 | 8.20e+03   | 3.03e+03   | 7.90e+03  \n",
      "            7.00e+01 | 8.19e+03   | 3.07e+03   | 7.85e+03  \n",
      "            7.50e+01 | 8.18e+03   | 3.06e+03   | 7.84e+03  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            8.00e+01 | 8.18e+03   | 3.04e+03   | 7.85e+03  \n",
      "            8.50e+01 | 8.17e+03   | 3.05e+03   | 7.82e+03  \n",
      "            9.00e+01 | 8.17e+03   | 3.02e+03   | 7.84e+03  \n",
      "            9.50e+01 | 8.16e+03   | 3.00e+03   | 7.86e+03  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1.00e+02 | 8.16e+03   | 3.00e+03   | 7.85e+03  \n",
      "            1.05e+02 | 8.16e+03   | 3.01e+03   | 7.84e+03  \n",
      "            1.08e+02 | 8.16e+03   | 3.00e+03   | 7.84e+03  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['iterations']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fgp.fit(stop_crit_improvement_threshold=1e3)\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:49.271862Z",
     "iopub.status.busy": "2025-04-25T22:13:49.271719Z",
     "iopub.status.idle": "2025-04-25T22:13:50.565462Z",
     "shell.execute_reply": "2025-04-25T22:13:50.565170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmean.shape = (2, 3, 4, 5, 128)\n",
      "pvar.shape = (2, 3, 4, 5, 128)\n",
      "q = 2.58\n",
      "ci_low.shape = (2, 3, 4, 5, 128)\n",
      "ci_high.shape = (2, 3, 4, 5, 128)\n",
      "l2rerror.shape = (2, 3, 4, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcov.shape = (2, 3, 4, 5, 5, 128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcov2.shape = (2, 3, 4, 5, 5, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "pmean,pvar,q,ci_low,ci_high = fgp.post_ci(x,confidence=0.99)\n",
    "print(\"pmean.shape = %s\"%str(tuple(pmean.shape)))\n",
    "print(\"pvar.shape = %s\"%str(tuple(pvar.shape)))\n",
    "print(\"q = %.2f\"%q)\n",
    "print(\"ci_low.shape = %s\"%str(tuple(ci_low.shape)))\n",
    "print(\"ci_high.shape = %s\"%str(tuple(ci_high.shape)))\n",
    "l2rerror = torch.linalg.norm(y-pmean,dim=-1)/torch.linalg.norm(y,dim=-1)\n",
    "print(\"l2rerror.shape = %s\"%str(tuple(l2rerror.shape)))\n",
    "pcov = fgp.post_cov(x,x)\n",
    "print(\"pcov.shape = %s\"%str(tuple(pcov.shape)))\n",
    "_range0,_rangen1 = torch.arange(pcov.size(-3)),torch.arange(pcov.size(-1))\n",
    "assert torch.allclose(pcov[...,_range0,_range0,:,:][...,_rangen1,_rangen1],pvar) and (pvar>=0).all()\n",
    "pcov2 = fgp.post_cov(x,z)\n",
    "print(\"pcov2.shape = %s\"%str(tuple(pcov2.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:50.566674Z",
     "iopub.status.busy": "2025-04-25T22:13:50.566600Z",
     "iopub.status.idle": "2025-04-25T22:13:50.570929Z",
     "shell.execute_reply": "2025-04-25T22:13:50.570686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcmean.shape = (2, 3, 4, 5)\n",
      "pcvar.shape = (2, 3, 4, 5)\n",
      "cci_low.shape = (2, 3, 4, 5)\n",
      "cci_high.shape = (2, 3, 4, 5)\n",
      "pccov.shape = (2, 3, 4, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "pcmean,pcvar,q,cci_low,cci_high = fgp.post_cubature_ci(confidence=0.99)\n",
    "print(\"pcmean.shape = %s\"%str(tuple(pcmean.shape)))\n",
    "print(\"pcvar.shape = %s\"%str(tuple(pcvar.shape)))\n",
    "print(\"cci_low.shape = %s\"%str(tuple(cci_low.shape)))\n",
    "print(\"cci_high.shape = %s\"%str(tuple(cci_high.shape)))\n",
    "pccov = fgp.post_cubature_cov()\n",
    "print(\"pccov.shape = %s\"%str(tuple(pccov.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and Increase Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:50.572147Z",
     "iopub.status.busy": "2025-04-25T22:13:50.572037Z",
     "iopub.status.idle": "2025-04-25T22:13:51.507617Z",
     "shell.execute_reply": "2025-04-25T22:13:51.507197Z"
    }
   },
   "outputs": [],
   "source": [
    "n_new = fgp.n*2\n",
    "pcov_future = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_future = fgp.post_var(x,n=n_new)\n",
    "pcvar_future = fgp.post_cubature_var(n=n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:51.509066Z",
     "iopub.status.busy": "2025-04-25T22:13:51.508931Z",
     "iopub.status.idle": "2025-04-25T22:13:52.535387Z",
     "shell.execute_reply": "2025-04-25T22:13:52.534928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 64])\n",
      "torch.Size([2, 3, 4, 32])\n",
      "torch.Size([2, 3, 4, 16])\n",
      "torch.Size([2, 3, 4, 8])\n",
      "torch.Size([2, 3, 4, 4])\n",
      "l2rerror.shape = (2, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "for _y in y_next:\n",
    "    print(_y.shape)\n",
    "fgp.add_y_next(y_next)\n",
    "l2rerror = torch.linalg.norm(y-fgp.post_mean(x),dim=-1)/torch.linalg.norm(y,dim=-1)\n",
    "print(\"l2rerror.shape = %s\"%str(tuple(l2rerror.shape)))\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_future)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_future)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:52.536902Z",
     "iopub.status.busy": "2025-04-25T22:13:52.536798Z",
     "iopub.status.idle": "2025-04-25T22:13:52.699546Z",
     "shell.execute_reply": "2025-04-25T22:13:52.699323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2rerror.shape = (2, 3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "data = fgp.fit(iterations=5,verbose=False)\n",
    "l2rerror = torch.linalg.norm(y-fgp.post_mean(x),dim=-1)/torch.linalg.norm(y,dim=-1)\n",
    "print(\"l2rerror.shape = %s\"%str(tuple(l2rerror.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T22:13:52.700711Z",
     "iopub.status.busy": "2025-04-25T22:13:52.700625Z",
     "iopub.status.idle": "2025-04-25T22:13:56.320110Z",
     "shell.execute_reply": "2025-04-25T22:13:56.319671Z"
    }
   },
   "outputs": [],
   "source": [
    "n_new = fgp.n*2\n",
    "pcov_new = fgp.post_cov(x,z,n=n_new)\n",
    "pvar_new = fgp.post_var(x,n=n_new)\n",
    "pcvar_new = fgp.post_cubature_var(n=n_new)\n",
    "x_next = fgp.get_x_next(n_new)\n",
    "y_next = [f(l,x_next[l]) for l in range(num_tasks)]\n",
    "fgp.add_y_next(y_next)\n",
    "assert torch.allclose(fgp.post_cov(x,z),pcov_new)\n",
    "assert torch.allclose(fgp.post_var(x),pvar_new)\n",
    "assert torch.allclose(fgp.post_cubature_var(),pcvar_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
